# ğŸ”„ Reflection & Reflexion Agents

This folder demonstrates self-improving AI agents that can critique and refine their own outputs - essential patterns for high-quality content generation and iterative problem-solving.

## ğŸ“š Notebooks Overview

### 1. **basic_reflection_agent.ipynb** - Reflection Pattern
**Difficulty:** â­â­â­ Advanced  
**Concepts:** Generate-Reflect loop, self-critique, iterative refinement

Core reflection pattern:
- **Generate** node - Creates initial content
- **Reflect** node - Critiques the output
- **Conditional routing** - Continue refining or finish
- **Iterative improvement** - Multiple rounds of enhancement

**Example:** Tweet generator that refines content through self-reflection until quality criteria are met.

**Use this when:** Building systems that need to iteratively improve outputs (writing, code, analysis).

---

### 2. **reflexion_agent.ipynb** - Reflexion Pattern (Advanced)
**Difficulty:** â­â­â­â­ Expert  
**Concepts:** Multi-trial learning, memory across attempts, failure analysis

Advanced self-improvement:
- **External Memory** - Stores learnings across trials
- **Trial-based learning** - Improves with each attempt
- **Failure analysis** - Learns from mistakes
- **Long-term memory** - Retains knowledge between runs

**Example:** Multi-trial problem solver that learns from failures and improves strategy over time.

**Use this when:** Complex tasks requiring learning from failures or multi-attempt problem-solving.

---

## ğŸ¯ Reflection vs Reflexion

### Reflection (Single-run improvement)
```
Generate â†’ Reflect â†’ Improve â†’ Reflect â†’ ... â†’ Done
   â†“          â†“          â†“
Draft    Critique   Better Draft
```

**Characteristics:**
- Single execution context
- Immediate improvements
- No memory between runs
- Perfect for content refinement

### Reflexion (Multi-trial learning)
```
Trial 1: Attempt â†’ Fail â†’ Analyze â†’ Store Learning
                                          â†“
Trial 2: Attempt (using learnings) â†’ Fail â†’ Analyze â†’ Store
                                                         â†“
Trial 3: Attempt (all learnings) â†’ Success!
```

**Characteristics:**
- Multiple execution trials
- Learns from failures
- Persistent memory
- Perfect for complex problem-solving

---

## ğŸ“Š Pattern Comparison

| Aspect | Reflection | Reflexion |
|--------|-----------|-----------|
| **Scope** | Single run | Multiple trials |
| **Memory** | Temporary (within run) | Persistent (across trials) |
| **Learning** | Immediate refinement | Accumulative learning |
| **Use Case** | Content quality | Problem solving |
| **Complexity** | â­â­â­ | â­â­â­â­ |
| **Iterations** | Within one invoke | Across multiple invokes |
| **Failure Handling** | Improve immediately | Learn for next trial |

---

## ğŸ”‘ Key Concepts

### 1. Reflection Loop

```python
def generate(state):
    # Create initial output
    return {"draft": llm.invoke(prompt)}

def reflect(state):
    # Critique the draft
    critique = llm.invoke(f"Review: {state['draft']}")
    return {"reflections": [critique]}

def should_continue(state):
    # Check if good enough
    if quality_check(state):
        return END
    return "generate"  # Try again
```

**Benefits:**
- âœ… Self-improving outputs
- âœ… Quality assurance
- âœ… Iterative refinement
- âœ… No human review needed

### 2. Reflexion Pattern

```python
class ReflexionState(TypedDict):
    task: str
    attempts: List[str]
    reflections: List[str]  # Learnings from failures
    solution: Optional[str]

def actor(state):
    # Try to solve using past reflections
    context = "\n".join(state["reflections"])
    attempt = llm.invoke(f"Task: {state['task']}\nLearnings: {context}")
    return {"attempts": [attempt]}

def evaluator(state):
    # Check if solution works
    if is_correct(state["attempts"][-1]):
        return {"solution": state["attempts"][-1]}
    return {}

def self_reflect(state):
    # Analyze failure and store learning
    reflection = llm.invoke(f"Why failed: {state['attempts'][-1]}")
    return {"reflections": [reflection]}
```

**Benefits:**
- âœ… Learns from mistakes
- âœ… Improves over trials
- âœ… Persistent knowledge
- âœ… More robust solutions

---

## ğŸ­ Use Cases

### Reflection Pattern
- âœ… **Content Generation** - Blog posts, tweets, emails
- âœ… **Code Review** - Self-reviewing generated code
- âœ… **Writing Quality** - Iterative document improvement
- âœ… **Creative Work** - Refining ideas and outputs
- âœ… **Translation** - Improving translation quality

### Reflexion Pattern
- âœ… **Problem Solving** - Math, logic, algorithms
- âœ… **Code Generation** - Complex coding tasks
- âœ… **Strategic Planning** - Multi-step strategy development
- âœ… **Research Tasks** - Finding answers through iteration
- âœ… **Game Playing** - Learning winning strategies

---

## ğŸ—ï¸ Architecture Patterns

### Basic Reflection Flow
```
START â†’ generate â†’ reflect â†’ [good enough?]
           â†‘                        â†“
           â””â”€â”€â”€â”€â”€â”€â”€â”€ NO â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â†“ YES
                                   END
```

### Reflexion Flow
```
Trial 1:
START â†’ actor â†’ evaluator â†’ [correct?]
                               â†“ NO
                          self_reflect â†’ store learning
                               
Trial 2 (with learnings):
START â†’ actor (using reflections) â†’ evaluator â†’ [correct?]
                                                    â†“ YES
                                                   END
```

---

## ğŸ“ Implementation Details

### Reflection State
```python
class ReflectionState(TypedDict):
    messages: Annotated[list, add_messages]
    # Messages include both drafts and reflections
```

### Reflexion State
```python
class ReflexionState(TypedDict):
    task: str
    attempts: List[str]  # All attempts
    reflections: List[str]  # Accumulated learnings
    iteration: int
    solution: Optional[str]
```

### Conditional Logic

```python
# Reflection
def should_continue(state):
    if meets_criteria(state["messages"][-1]):
        return END
    if len(state["messages"]) > MAX_ITERATIONS:
        return END
    return "generate"

# Reflexion
def should_continue(state):
    if state.get("solution"):
        return END
    if state["iteration"] >= MAX_TRIALS:
        return END
    return "actor"
```

---

## ğŸš€ Advanced Features

### Quality Metrics
```python
def assess_quality(content):
    # Check length, clarity, engagement
    score = llm.invoke(f"Rate 1-10: {content}")
    return int(score) >= 8
```

### Learning Storage
```python
# Persistent reflexion memory
from langgraph.checkpoint.sqlite import SqliteSaver

memory = SqliteSaver.from_conn_string("reflexion.db")
app = graph.compile(checkpointer=memory)
```

### Human Override
```python
app = graph.compile(
    checkpointer=memory,
    interrupt_before=["generate"]  # Review before each attempt
)
```

---

## ğŸ“Š Performance Comparison

| Metric | No Reflection | Reflection | Reflexion |
|--------|---------------|------------|-----------|
| **Quality** | â­â­ | â­â­â­â­ | â­â­â­â­â­ |
| **Speed** | Fast | Medium | Slow |
| **Cost** | Low | Medium | High |
| **Reliability** | Low | High | Very High |
| **Learning** | None | Per-run | Across runs |

---

## ğŸ“ Learning Path

```
1. basic_reflection_agent.ipynb
   â†“ (Master single-run improvement)
   - Understand generate-reflect loop
   - Implement quality checks
   - Practice iterative refinement
   
2. reflexion_agent.ipynb
   â†“ (Master multi-trial learning)
   - Add persistent memory
   - Implement failure analysis
   - Build learning systems
```

---

## ğŸ“– Research Papers

- **Reflection**: "Self-Refine: Iterative Refinement with Self-Feedback"
- **Reflexion**: "Reflexion: Language Agents with Verbal Reinforcement Learning"

---

## ğŸ¯ Next Steps

After mastering reflection patterns:
1. **Combine with Tools** - Self-improving agents with external tools
2. **Multi-Agent Collaboration** - Agents that critique each other
3. **Human-in-the-Loop** - Human feedback in reflection loop
4. **Production Deployment** - Scale with proper monitoring

---

## ğŸ’¡ Best Practices

### For Reflection
1. Set maximum iterations (avoid infinite loops)
2. Define clear quality criteria
3. Use specific reflection prompts
4. Monitor LLM costs

### For Reflexion
1. Store learnings persistently
2. Limit trial attempts
3. Clear failure definitions
4. Track improvement metrics

---

**ğŸ’¡ Tip:** Start with `basic_reflection_agent.ipynb` for immediate output improvement, then explore `reflexion_agent.ipynb` for complex problem-solving that benefits from learning across attempts.
