{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f5af3fc",
   "metadata": {},
   "source": [
    "### ğŸ§  What Is a Reflection (Reflective) Agent Pattern?\n",
    "\n",
    "A reflective agent is an intelligent agent that can reason about itself â€” that is, it can:\n",
    "\n",
    "Generate actions or plans,\n",
    "\n",
    "Reflect on (i.e., think about or evaluate) what it has generated, and\n",
    "\n",
    "Modify or improve its behavior accordingly.\n",
    "\n",
    "So yes â€” as you said:\n",
    "\n",
    "Itâ€™s an agent that can generate something, reflect on what it has generated, and check or adjust it.\n",
    "\n",
    "### A basic relection agent contains a \n",
    "1.reflector \n",
    "\n",
    "2.generator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb64bc8",
   "metadata": {},
   "source": [
    "![Reflection Agent Pattern](reflection.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79dbdb2c",
   "metadata": {},
   "source": [
    "here you can see in the diagram here is a generete tweet llm node which is generator agent and criticize tweet agent is relfector agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a048c843",
   "metadata": {},
   "source": [
    "### types of relection\n",
    "### 1. Simple Reflection Agent\n",
    "What it means\n",
    "\n",
    "A â€œsimple reflection agentâ€ is an agent that:\n",
    "\n",
    "generates an output/action/decision,\n",
    "\n",
    "then reflects on that output (i.e., evaluates it, checks for errors/gaps),\n",
    "\n",
    "optionally refines its output or updates its strategy.\n",
    "This is more advanced than a pure reflex agent (which just responds) because it has a feedback loop.\n",
    "\n",
    "How it works (pattern)\n",
    "\n",
    "Generate: Agent perceives environment or receives input â†’ produces an action or response.\n",
    "\n",
    "Reflect/Evaluate: Agent examines the result: â€œDid this meet the criteria? Are there mistakes? What could be improved?â€\n",
    "\n",
    "Refine/Act: Based on the evaluation, the agent corrects or improves the output or modifies its internal rules/knowledge.\n",
    "\n",
    "Possibly repeat until some stopping criterion (quality threshold, number of iterations) is met.\n",
    "\n",
    "Research / Articles\n",
    "\n",
    "The article â€œAgentic Design Patterns Part 2: Reflectionâ€ from DeepLearning.AI explains this kind of pattern: â€œthe self-reflection process allows the LLM to spot gaps and improve its output â€¦ repeating the criticism/rewrite processâ€. \n",
    "DeepLearning.ai\n",
    "\n",
    "Also, â€œImplementing the Reflection Pattern in Agentic AI Applicationsâ€ describes how this pattern helps ensure correctness of outputs (especially for language agents) by adding a postâ€step evaluation. \n",
    "AIMon Labs\n",
    "\n",
    "When & why youâ€™d use it\n",
    "\n",
    "When your agent/task is complex enough that one pass likely has errors or could be improved.\n",
    "\n",
    "When you need better reliability (e.g., text generation, code generation, decisionâ€making) rather than just fast reflex responses.\n",
    "\n",
    "It's still relatively simple compared to full metaâ€reasoning: no heavy architecture changes, just add an evaluation/reflection phase.\n",
    "\n",
    "### 2. â€œReflexionâ€ Agent (as a more advanced form)\n",
    "What it means\n",
    "\n",
    "Here â€œReflexionâ€ (note the spelling) refers to a more advanced agent that doesnâ€™t just reflect once, but learns across trials â€” it uses its reflections (from previous runs) as input for future decisions. So it has longerâ€term memory of reflections and uses them to improve over time.\n",
    "\n",
    "How it works (pattern)\n",
    "\n",
    "Agent runs a trial: generates an output, takes action, observes outcome.\n",
    "\n",
    "After the trial, it evaluates what happened (error, success, metrics).\n",
    "\n",
    "It then stores a reflection (in natural language or structured form) about what went well / what went wrong.\n",
    "\n",
    "In subsequent trials, it uses its stored reflections + past trajectories to plan or decide better.\n",
    "\n",
    "Over time, performance improves (learning from reflections + experience).\n",
    "\n",
    "Research / Articles\n",
    "\n",
    "The blog â€œReflexion: Agents in Actionâ€ describes this: an actor model uses past trajectories and longâ€term memory of verbal reflections to refine future actions, leading to improved performance. \n",
    "Unalarming\n",
    "\n",
    "The paper â€œExtending Environments to Measure Self-reflection in Reinforcement Learningâ€ describes agents which must reason about their own hypothetical behaviour and reflections to succeed in â€œextended environmentsâ€. \n",
    "PhilArchive\n",
    "+1\n",
    "\n",
    "Another paper â€œSelf-Reflection in LLM Agents: Effects on Problemâ€Solvingâ€ shows that agents with selfâ€reflection capabilities perform better. \n",
    "AI Models\n",
    "+1\n",
    "\n",
    "When & why youâ€™d use it\n",
    "\n",
    "When you have multiple trials of the same or similar tasks, and you want the agent to improve over time (rather than just one shot).\n",
    "\n",
    "When you can afford memory/storage of past runs and the reflection phase adds overhead but gives performance gains.\n",
    "\n",
    "For research settings, or complex workflows (multiâ€step reasoning, code generation, planning) where learning from past failures matters.\n",
    "\n",
    "### 3. Language Agent with Reflection / Research Capabilities\n",
    "What it means\n",
    "\n",
    "This refers to an agent (often built on a large language model) that uses reflection or metaâ€reasoning in the language domain, possibly combining retrieval, reasoning, planning, reflection, and even researchâ€style workflows (look up information, generate, critique, iterate).\n",
    "So itâ€™s like a â€œlanguage agentâ€ (works with text, LLMs) + reflection + maybe tool usage / external data.\n",
    "\n",
    "How it works (pattern)\n",
    "\n",
    "The agent receives a languageâ€based task: e.g., \"Write a report\", \"Answer this multiâ€hop question\", \"Generate code\".\n",
    "\n",
    "It generates an initial response (via its LLM).\n",
    "\n",
    "It reflects: Critiques itself, either by internal rubric, external test/feedback, tool execution, or retrieval of data to check accuracy.\n",
    "\n",
    "It refines: Creates improved response (maybe multiple iterations).\n",
    "\n",
    "It may also research: retrieve external information, incorporate new data, update its internal memory/knowledge.\n",
    "\n",
    "In more advanced setups: it may store its reflections for future tasks, adapt its behaviour based on past tasks (combining with the â€œreflexionâ€ style).\n",
    "\n",
    "May use a â€œreflectorâ€ module (separate agent or model) to check outputs.\n",
    "\n",
    "Research / Articles\n",
    "\n",
    "The paper â€œRe-ReST: Reflection-Reinforced Self-Training for Language Agentsâ€ presents a method for language agents to selfâ€train: the agent produces outputs, a â€œreflectorâ€ improves them, then they are used for training. \n",
    "arXiv\n",
    "\n",
    "â€œGenerative Agents: Interactive Simulacra of Human Behaviorâ€ uses language agents that store memories, synthesize reflections, and retrieve them to plan behaviour. \n",
    "arXiv\n",
    "\n",
    "The blog â€œA Guide to Reflection Agents Using LlamaIndexâ€ covers â€œIntrospective Agentsâ€ built on LLMs: generate â†’ reflect â†’ embed improvements. \n",
    "Analytics Vidhya\n",
    "\n",
    "The learning path article â€œHow to Become an Agentic AI Expert in 2025?â€ describes adding reflection workflows to retrievalâ€augmented generation (RAG) systems. \n",
    "Analytics Vidhya\n",
    "\n",
    "When & why youâ€™d use it\n",
    "\n",
    "When your agent is languageâ€centric (text generation, code generation, multiâ€step reasoning, QA) and you want high quality and reliability.\n",
    "\n",
    "When you have access to tools, retrieval sources, and want your agent to behave more like a â€œresearcherâ€ or â€œwriterâ€ (not just a quick answerer).\n",
    "\n",
    "When you can afford more complexity (iteration, memory, external tools) for higher performance or autonomy.\n",
    "\n",
    "ğŸ” Comparison & Summary\n",
    "Pattern Type\tKey Features\tComplexity\tUse Case\n",
    "Simple Reflection Agent\tOne loop: generate â†’ reflect â†’ refine\tLowâ€Medium\tSingle task, need better quality\n",
    "Reflexion Agent\tMultiâ€trial learning: generate â†’ reflect â†’ store â†’ improved next run\tMediumâ€High\tRepeated tasks, learning from history\n",
    "Language Agent w/ Reflection & Research\tLLM + tools + retrieval + reflection + memory + refinement\tHigh\tComplex language tasks, researchâ€style workflows, autonomy\n",
    "ğŸ§‘â€ğŸ’» How this relates to your work (GestureSpeak, etc)\n",
    "\n",
    "Since you are working on models (CNN, EfficientNet, YOLO) and building APIs, hereâ€™s how you might consider these patterns:\n",
    "\n",
    "If you ever build an agent (or a module) that generates something (like a sign recognition result, or transcription) and you want a reflection step (check if the output makes sense, maybe correct misâ€classifications), you could adopt the simple reflection agent pattern.\n",
    "\n",
    "If you deploy multiple runs (e.g., realâ€time gesture sequences), you might implement a â€œreflexionâ€ style where the system remembers past mistakes and adjusts (thresholds, filter logic) over time.\n",
    "\n",
    "If you ever integrate a language module (for example, generating explanatory text from gestures, or an interactive chatbot for sign language) you could make a language agent with reflection â€” where it retrieves information, generates explanation, reflects on correctness (perhaps with a rubric), and improves the output."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b56ccfc9",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "42640237",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "![Reflection Agent Pattern](reflection1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e36714",
   "metadata": {},
   "source": [
    "### examples use case"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3070735",
   "metadata": {},
   "source": [
    "### Chains for basic relection agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368bdcb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "generation_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a twitter techie influencer assistant tasked with writing excellent twitter posts.\"\n",
    "            \" Generate the best twitter post possible for the user's request.\"\n",
    "            \" If the user provides critique, respond with a revised version of your previous attempts.\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "reflection_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a viral twitter influencer grading a tweet. Generate critique and recommendations for the user's tweet.\"\n",
    "            \"Always provide detailed recommendations, including requests for length, virality, style, etc.\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\")\n",
    "generation_chain = generation_prompt | llm\n",
    "reflection_chain = reflection_prompt | llm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ec5cc5",
   "metadata": {},
   "source": [
    "examples relfection agent uisng the previous chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d5a300",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Sequence\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.messages import BaseMessage, HumanMessage\n",
    "from langgraph.graph import END, MessageGraph\n",
    "from chains import generation_chain, reflection_chain\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "REFLECT = \"reflect\"\n",
    "GENERATE = \"generate\"\n",
    "graph = MessageGraph()\n",
    "\n",
    "def generate_node(state):\n",
    "    return generation_chain.invoke({\n",
    "        \"messages\": state\n",
    "    })\n",
    "\n",
    "\n",
    "def reflect_node(state):\n",
    "    response = reflection_chain.invoke({\n",
    "        \"messages\": state\n",
    "    })\n",
    "    return [HumanMessage(content=response.content)]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c712a15e",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langraph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
