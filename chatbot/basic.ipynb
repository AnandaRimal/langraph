{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5285626e",
   "metadata": {},
   "source": [
    "# üí¨ LangGraph Chatbot: Basic Implementation\n",
    "\n",
    "Build a simple conversational AI agent using LangGraph and Google Gemini.\n",
    "\n",
    "## üéØ What You'll Learn\n",
    "\n",
    "1. **Chatbot State** - Managing conversation history\n",
    "2. **add_messages** - Automatic message appending\n",
    "3. **Simple Graph Structure** - Linear chatbot flow\n",
    "4. **LLM Integration** - Connecting Google Gemini\n",
    "5. **Interactive Loop** - Continuous conversation\n",
    "\n",
    "## ‚ú® What This Chatbot Does\n",
    "\n",
    "- ‚úÖ Takes user input\n",
    "- ‚úÖ Sends to Google Gemini LLM\n",
    "- ‚úÖ Returns AI response\n",
    "- ‚úÖ Maintains conversation context\n",
    "- ‚úÖ Runs in a continuous loop\n",
    "\n",
    "**Note:** This is a basic chatbot WITHOUT tools. It only does text conversation.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b01dc818",
   "metadata": {},
   "source": [
    "## üì¶ Step 1: Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a7027d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [HumanMessage(content='hello', additional_kwargs={}, response_metadata={}, id='183052e0-9f16-43e9-b05d-aad67969d9ea'), AIMessage(content='Hello! How can I help you today?', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'grounding_metadata': {}, 'model_provider': 'google_genai'}, id='lc_run--5d81eefd-603a-4c60-9a82-717bdccb3188-0', usage_metadata={'input_tokens': 2, 'output_tokens': 32, 'total_tokens': 34, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 23}})]}\n"
     ]
    }
   ],
   "source": [
    "# LangGraph imports\n",
    "from typing import TypedDict, Annotated\n",
    "from langgraph.graph import add_messages, StateGraph, END\n",
    "\n",
    "# LangChain imports\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "# Environment\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load API keys from .env file\n",
    "load_dotenv()\n",
    "\n",
    "print(\"‚úÖ Dependencies imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74987f88",
   "metadata": {},
   "source": [
    "## üß† Step 2: Initialize LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23be0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Google Gemini model\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\")\n",
    "\n",
    "print(\"‚úÖ Gemini 2.5 Flash model initialized!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ccb13c",
   "metadata": {},
   "source": [
    "## üèóÔ∏è Step 3: Define State\n",
    "\n",
    "**Key Feature:** `add_messages` reducer\n",
    "- Automatically appends new messages to the list\n",
    "- Maintains full conversation history\n",
    "- No manual list management needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88322ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define chatbot state with message history\n",
    "class BasicChatState(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "    # ‚Üë This annotation means:\n",
    "    # - messages is a list\n",
    "    # - add_messages automatically appends new messages\n",
    "    # - No need to manually manage message history\n",
    "\n",
    "print(\"‚úÖ State schema defined with automatic message handling!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52045a8",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è Step 4: Define Chatbot Node\n",
    "\n",
    "The node function:\n",
    "1. Receives current state (with message history)\n",
    "2. Sends all messages to the LLM\n",
    "3. Returns the LLM's response\n",
    "4. State automatically merges the new message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d8898b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chatbot(state: BasicChatState):\n",
    "    \"\"\"\n",
    "    Chatbot node:\n",
    "    - Takes state with message history\n",
    "    - Invokes LLM with all messages (for context)\n",
    "    - Returns new AI message\n",
    "    \"\"\"\n",
    "    return {\n",
    "        \"messages\": [llm.invoke(state[\"messages\"])]\n",
    "    }\n",
    "\n",
    "print(\"‚úÖ Chatbot node function defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a1804c4",
   "metadata": {},
   "source": [
    "## üîß Step 5: Build the Graph\n",
    "\n",
    "Simple linear flow:\n",
    "```\n",
    "START ‚Üí chatbot ‚Üí END\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f959f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create graph\n",
    "graph = StateGraph(BasicChatState)\n",
    "\n",
    "# Add chatbot node\n",
    "graph.add_node(\"chatbot\", chatbot)\n",
    "\n",
    "# Set entry point\n",
    "graph.set_entry_point(\"chatbot\")\n",
    "\n",
    "# Add edge to END (conversation ends after each response)\n",
    "graph.add_edge(\"chatbot\", END)\n",
    "\n",
    "# Compile\n",
    "app = graph.compile()\n",
    "\n",
    "print(\"‚úÖ Graph compiled!\")\n",
    "print(\"\\nüìä Graph Structure:\")\n",
    "print(\"   START ‚Üí chatbot ‚Üí END\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a63120f4",
   "metadata": {},
   "source": [
    "## üí¨ Step 6: Run the Chat Loop\n",
    "\n",
    "Interactive conversation loop:\n",
    "- Takes user input\n",
    "- Creates HumanMessage\n",
    "- Invokes graph\n",
    "- Prints full response\n",
    "\n",
    "**Type \"exit\" or \"end\" to quit**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7aca6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ü§ñ Chatbot started! Type 'exit' or 'end' to quit.\\n\")\n",
    "\n",
    "while True: \n",
    "    user_input = input(\"You: \")\n",
    "    \n",
    "    # Check for exit commands\n",
    "    if user_input.lower() in [\"exit\", \"end\"]:\n",
    "        print(\"üëã Goodbye!\")\n",
    "        break\n",
    "    else: \n",
    "        # Run the graph with user message\n",
    "        result = app.invoke({\n",
    "            \"messages\": [HumanMessage(content=user_input)]\n",
    "        })\n",
    "        \n",
    "        # Print the full result (shows all messages)\n",
    "        print(f\"\\nAI: {result['messages'][-1].content}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebcd119c",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéì Key Concepts Explained\n",
    "\n",
    "### 1Ô∏è‚É£ **add_messages Reducer**\n",
    "\n",
    "```python\n",
    "messages: Annotated[list, add_messages]\n",
    "```\n",
    "\n",
    "This special annotation automatically handles message history:\n",
    "- **Without it**: You'd need to manually append each message\n",
    "- **With it**: New messages are automatically added to the list\n",
    "- **Benefits**: Cleaner code, less error-prone\n",
    "\n",
    "### 2Ô∏è‚É£ **State Flow**\n",
    "\n",
    "```\n",
    "User Input ‚Üí HumanMessage ‚Üí Graph Invoke ‚Üí LLM Processing ‚Üí AI Message ‚Üí State Update\n",
    "```\n",
    "\n",
    "Each invoke:\n",
    "1. Adds HumanMessage to state\n",
    "2. Chatbot node processes all messages\n",
    "3. Returns AIMessage\n",
    "4. State automatically merges new message\n",
    "5. Full history preserved for next turn\n",
    "\n",
    "### 3Ô∏è‚É£ **Why This Pattern?**\n",
    "\n",
    "| Aspect | Benefit |\n",
    "|--------|---------|\n",
    "| **State Persistence** | Conversation context maintained |\n",
    "| **Automatic Merging** | No manual list operations |\n",
    "| **Clean Code** | Single node handles all logic |\n",
    "| **Scalable** | Easy to add more nodes later |\n",
    "\n",
    "---\n",
    "\n",
    "## üöÄ Next Steps\n",
    "\n",
    "This basic chatbot can be extended with:\n",
    "\n",
    "1. **Tools** - Add web search, calculations, etc.\n",
    "2. **Memory** - Persist conversations across sessions\n",
    "3. **Conditional Routing** - Different behaviors based on input\n",
    "4. **Human-in-the-Loop** - Approval workflows\n",
    "5. **Multi-Agent** - Multiple specialized chatbots\n",
    "\n",
    "Check out `chatbotwith_tools.ipynb` for the next level! üéØ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langraph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
